<p>Benchmark NLU (Natural Language Understanding) is a standardized evaluation method used to measure the performance of natural language processing (NLP) models on a variety of tasks. Boolean questions are included on benchmark NLU (Natural Language Understanding) tasks because they represent a fundamental and widely used type of question in natural language. Boolean questions are questions that can be answered with a simple "yes" or "no" response. Boolean questions in NLU benchmarks allows researchers and developers to evaluate and compare the performance of different NLU systems on this important task. This helps to advance the state of the art in NLU and ultimately leads to better natural language processing applications.</p>

<p><b>BoolQ is a question answering dataset</b> for yes/no questions. These questions are naturally occurring ---they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging.</p>

<p>Each example is a triplet of (question, passage, answer), with the title of the page as optional additional context. The text-pair classification setup is similar to existing natural language inference tasks. You can get all the data <a href="https://drive.google.com/drive/folders/1UWJ8LNCcygeJot9SE1nmYfemov3ND9pP?usp=sharing">HERE.</a></p>

<p>The files are:</p>
<ul dir="auto">
<li><strong>train_split.csv</strong>: 8500 labeled training examples</li>
<li><strong>train.csv</strong>: 9427 unlabeled training examples</li>
<li><strong>dev.csv</strong>: 3270 unlabeled test examples</li>
</ul>
